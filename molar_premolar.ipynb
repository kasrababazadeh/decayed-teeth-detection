{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av5OBWsb2Rqw",
        "outputId": "3065a92d-4d7c-4f35-9268-5ab59b8ef25b"
      },
      "outputs": [],
      "source": [
        "# if you are using .DCM images\n",
        "!pip install pydicom"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "AUGMENT YOUR DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulIpr9cn5K-E",
        "outputId": "e7bab160-105b-412b-ec8e-6c0f890b54a9"
      },
      "outputs": [],
      "source": [
        "import pydicom\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "def augment(dicom_path, output_path):\n",
        "  dicom_data = pydicom.dcmread(dicom_path)\n",
        "  original_filename, extension = os.path.splitext(os.path.basename(dicom_path))\n",
        "  image = dicom_data.pixel_array\n",
        "  image = np.expand_dims(image, axis=-1)\n",
        "  datagen = ImageDataGenerator(\n",
        "      vertical_flip=True\n",
        "      # horizontal_flip=True\n",
        "  )\n",
        "  augmented_image = datagen.apply_transform(image, transform_parameters={\n",
        "            # \"flip_horizontal\": True\n",
        "            \"flip_vertical\": True\n",
        "        })\n",
        "  augmented_image = np.squeeze(augmented_image, axis=-1)\n",
        "  dicom_data.PixelData = augmented_image.tobytes()\n",
        "  new_filename = original_filename + \"_molarv\" + extension\n",
        "  new_dicom_file_path = os.path.join(output_path, new_filename)\n",
        "  dicom_data.save_as(new_dicom_file_path)\n",
        "  print(f\"Saved augmented image as {output_path}\")\n",
        "input_directory = \"/path/to/images\"\n",
        "output_directory = \"/path/to/augmented_images\"\n",
        "for filename in os.listdir(input_directory):\n",
        "    if filename.endswith(\".DCM\"):\n",
        "      dicom_path = os.path.join(input_directory, filename)\n",
        "      augment(dicom_path, output_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MOVE and ORGANIZE YOUR DATA IF NEEDED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGRaC5qP1EYq",
        "outputId": "effcb66f-68a9-4358-e420-4a23a9a0479f"
      },
      "outputs": [],
      "source": [
        "source_directory = '/path/to/source_directory'\n",
        "output_directory = '/path/to/output_directory'\n",
        "# List DICOM files in the source directory\n",
        "dicom_files = [os.path.join(source_directory, filename) for filename in os.listdir(source_directory) if filename.endswith('.DCM')]\n",
        "# c = 0\n",
        "for dicom_file in dicom_files:\n",
        "  ds = pydicom.dcmread(dicom_file)\n",
        "  # c += 1\n",
        "  file_name = os.path.splitext(os.path.basename(dicom_file))[0]\n",
        "  # You can manipulate the DICOM data if needed.\n",
        "  new_name = file_name + '.DCM'\n",
        "  new_filename = os.path.join(output_directory, new_name)\n",
        "  ds.save_as(new_filename)\n",
        "# print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LOAD YOUR DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o9D3tjM5Yja"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pydicom\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "path = \"/path/to/your_images\"\n",
        "images = []\n",
        "labels = []\n",
        "for filename in os.listdir(path):\n",
        "    ds = pydicom.read_file(os.path.join(path, filename))\n",
        "    if 'premolar' in filename:\n",
        "      labels.append(1)\n",
        "    elif 'molar' in filename:\n",
        "      labels.append(2)\n",
        "    pixel_array = ds.pixel_array.astype(np.float32)\n",
        "    image = Image.fromarray(pixel_array)\n",
        "    size = (200 ,200)\n",
        "    image = image.resize(size)\n",
        "    # plt.imshow(image, cmap=\"gray\")\n",
        "    # plt.axis('off')\n",
        "    # plt.show()\n",
        "    image = np.array(image)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "    image = preprocess_input(image)\n",
        "    images.append(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AUQTh3KEbFn",
        "outputId": "dc861e1a-cfc5-43db-8293-df82ea9622f0"
      },
      "outputs": [],
      "source": [
        "images = np.array(images)\n",
        "images = np.stack(images, axis=0)\n",
        "print(len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL9XuAn4JhfQ",
        "outputId": "103e1214-6ddb-41fe-fd6f-54631df2e338"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize the LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the LabelEncoder to your class labels\n",
        "label_encoder.fit(labels)\n",
        "\n",
        "# Get the encoded labels\n",
        "labels = label_encoder.transform(labels)\n",
        "\n",
        "# Print the encoded labels\n",
        "labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc8skBrZJsGH",
        "outputId": "ab18ed8b-2ede-4f57-ece1-d65bc4a51bae"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
        "\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=23, stratify=labels)\n",
        "\n",
        "print(\"Train data shape:\", train_images.shape)\n",
        "print(\"Train labels shape:\", train_labels.shape)\n",
        "print(\"Validation data shape:\", val_images.shape)\n",
        "print(\"Validation labels shape:\", val_labels.shape)\n",
        "# print(\"Test data shape:\", test_images.shape)\n",
        "# print(\"Test labels shape:\", test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IjqoET0JtVi",
        "outputId": "49a2ef57-71f7-410a-c614-9fd4b14f12bf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l1_l2, l2, l1\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, AveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(200, 200, 3))\n",
        "\n",
        "model = keras.Sequential([\n",
        "        base_model,\n",
        "        layers.BatchNormalization(),\n",
        "        layers.AveragePooling2D(pool_size=(2, 2), padding='same'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation='sigmoid')])\n",
        "\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "# for layer in base_model.layers[-10:]:\n",
        "#     layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.00002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, batch_size=32, epochs=100, validation_data=(val_images, val_labels), callbacks=[early_stopping])\n",
        "model.save('/path/to/molar_premolar_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "h9y2SrYBJ4WP",
        "outputId": "b0d95bae-2889-4267-eb8e-7125b8554223"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "# plt.plot(epochs, train_loss, 'b-', label='Training Loss')\n",
        "# plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.plot(epochs, train_accuracy, 'b--', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r--', label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Metrics')\n",
        "plt.title('Training and Validation Metrics')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2LJ2PLMKApc",
        "outputId": "faa8301a-00c1-46ba-92af-f9130007063d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "# unfreeze layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.000002), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, batch_size=32, epochs=100, validation_data=(val_images, val_labels), callbacks=[early_stopping])\n",
        "model.save('/path/to/fine_tuned_molar_premolar_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ALzKaRomT9p-",
        "outputId": "697022c4-86fe-44bd-aee9-194a7094707a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "train_accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "plt.plot(epochs, train_loss, 'b-', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
        "plt.plot(epochs, train_accuracy, 'b--', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r--', label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Metrics')\n",
        "plt.title('Training and Validation Metrics')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
